{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**MLP**"
      ],
      "metadata": {
        "id": "We4cMenyYLwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define the MLP model\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(3 * 32 * 32, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 3 * 32 * 32)  # Flatten the input\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Download and prepare the CIFAR-10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# Initialize the MLP model, loss function, and optimizer\n",
        "model = MLP()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:\n",
        "            print(f'Epoch {epoch + 1}, Batch {i + 1}: Loss {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Training finished')\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "correct = 0\n",
        "total = 0\n",
        "test_loss = 0.0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "average_test_loss = test_loss / len(testloader)\n",
        "\n",
        "print(f'Accuracy on the test set: {accuracy:.2f}%')\n",
        "print(f'Average loss on the test set: {average_test_loss:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLDlg-fbeMMf",
        "outputId": "de78fb72-a0bf-4c83-eada-d30a19743cc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 77061902.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Epoch 1, Batch 2000: Loss 1.909\n",
            "Epoch 1, Batch 4000: Loss 1.693\n",
            "Epoch 1, Batch 6000: Loss 1.634\n",
            "Epoch 1, Batch 8000: Loss 1.590\n",
            "Epoch 1, Batch 10000: Loss 1.565\n",
            "Epoch 1, Batch 12000: Loss 1.541\n",
            "Epoch 2, Batch 2000: Loss 1.438\n",
            "Epoch 2, Batch 4000: Loss 1.425\n",
            "Epoch 2, Batch 6000: Loss 1.456\n",
            "Epoch 2, Batch 8000: Loss 1.413\n",
            "Epoch 2, Batch 10000: Loss 1.407\n",
            "Epoch 2, Batch 12000: Loss 1.390\n",
            "Epoch 3, Batch 2000: Loss 1.281\n",
            "Epoch 3, Batch 4000: Loss 1.296\n",
            "Epoch 3, Batch 6000: Loss 1.316\n",
            "Epoch 3, Batch 8000: Loss 1.286\n",
            "Epoch 3, Batch 10000: Loss 1.323\n",
            "Epoch 3, Batch 12000: Loss 1.308\n",
            "Epoch 4, Batch 2000: Loss 1.186\n",
            "Epoch 4, Batch 4000: Loss 1.204\n",
            "Epoch 4, Batch 6000: Loss 1.226\n",
            "Epoch 4, Batch 8000: Loss 1.221\n",
            "Epoch 4, Batch 10000: Loss 1.221\n",
            "Epoch 4, Batch 12000: Loss 1.218\n",
            "Epoch 5, Batch 2000: Loss 1.114\n",
            "Epoch 5, Batch 4000: Loss 1.110\n",
            "Epoch 5, Batch 6000: Loss 1.139\n",
            "Epoch 5, Batch 8000: Loss 1.138\n",
            "Epoch 5, Batch 10000: Loss 1.155\n",
            "Epoch 5, Batch 12000: Loss 1.149\n",
            "Epoch 6, Batch 2000: Loss 1.019\n",
            "Epoch 6, Batch 4000: Loss 1.051\n",
            "Epoch 6, Batch 6000: Loss 1.059\n",
            "Epoch 6, Batch 8000: Loss 1.071\n",
            "Epoch 6, Batch 10000: Loss 1.086\n",
            "Epoch 6, Batch 12000: Loss 1.085\n",
            "Epoch 7, Batch 2000: Loss 0.943\n",
            "Epoch 7, Batch 4000: Loss 0.979\n",
            "Epoch 7, Batch 6000: Loss 0.984\n",
            "Epoch 7, Batch 8000: Loss 0.998\n",
            "Epoch 7, Batch 10000: Loss 1.029\n",
            "Epoch 7, Batch 12000: Loss 1.039\n",
            "Epoch 8, Batch 2000: Loss 0.871\n",
            "Epoch 8, Batch 4000: Loss 0.916\n",
            "Epoch 8, Batch 6000: Loss 0.933\n",
            "Epoch 8, Batch 8000: Loss 0.936\n",
            "Epoch 8, Batch 10000: Loss 0.951\n",
            "Epoch 8, Batch 12000: Loss 0.945\n",
            "Epoch 9, Batch 2000: Loss 0.803\n",
            "Epoch 9, Batch 4000: Loss 0.856\n",
            "Epoch 9, Batch 6000: Loss 0.873\n",
            "Epoch 9, Batch 8000: Loss 0.874\n",
            "Epoch 9, Batch 10000: Loss 0.889\n",
            "Epoch 9, Batch 12000: Loss 0.893\n",
            "Epoch 10, Batch 2000: Loss 0.733\n",
            "Epoch 10, Batch 4000: Loss 0.791\n",
            "Epoch 10, Batch 6000: Loss 0.809\n",
            "Epoch 10, Batch 8000: Loss 0.815\n",
            "Epoch 10, Batch 10000: Loss 0.832\n",
            "Epoch 10, Batch 12000: Loss 0.835\n",
            "Training finished\n",
            "Accuracy on the test set: 53.67%\n",
            "Average loss on the test set: 1.5095\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CNN**"
      ],
      "metadata": {
        "id": "f32CbzS2kn_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define the CNN architecture\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.fc1 = nn.Linear(32 * 8 * 8, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 32 * 8 * 8)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Download and prepare the CIFAR-10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# Initialize the CNN model, loss function, and optimizer\n",
        "model = CNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Train the CNN model\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:\n",
        "            print(f'Epoch {epoch + 1}, Batch {i + 1}: Loss {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Training finished')\n",
        "\n",
        "# Evaluate the CNN model on the test set\n",
        "correct = 0\n",
        "total = 0\n",
        "test_loss = 0.0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "accuracy_cnn = 100 * correct / total\n",
        "average_test_loss_cnn = test_loss / len(testloader)\n",
        "\n",
        "print(f'Accuracy of CNN on the test set: {accuracy_cnn:.2f}%')\n",
        "print(f'Average loss of CNN on the test set: {average_test_loss_cnn:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsglZ3NVkqjM",
        "outputId": "35af9a50-582f-4c65-a8de-b1358008c535"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 48930678.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Epoch 1, Batch 2000: Loss 2.014\n",
            "Epoch 1, Batch 4000: Loss 1.586\n",
            "Epoch 1, Batch 6000: Loss 1.448\n",
            "Epoch 1, Batch 8000: Loss 1.393\n",
            "Epoch 1, Batch 10000: Loss 1.307\n",
            "Epoch 1, Batch 12000: Loss 1.229\n",
            "Epoch 2, Batch 2000: Loss 1.129\n",
            "Epoch 2, Batch 4000: Loss 1.095\n",
            "Epoch 2, Batch 6000: Loss 1.078\n",
            "Epoch 2, Batch 8000: Loss 1.047\n",
            "Epoch 2, Batch 10000: Loss 1.026\n",
            "Epoch 2, Batch 12000: Loss 1.019\n",
            "Epoch 3, Batch 2000: Loss 0.889\n",
            "Epoch 3, Batch 4000: Loss 0.887\n",
            "Epoch 3, Batch 6000: Loss 0.918\n",
            "Epoch 3, Batch 8000: Loss 0.891\n",
            "Epoch 3, Batch 10000: Loss 0.877\n",
            "Epoch 3, Batch 12000: Loss 0.882\n",
            "Epoch 4, Batch 2000: Loss 0.745\n",
            "Epoch 4, Batch 4000: Loss 0.764\n",
            "Epoch 4, Batch 6000: Loss 0.764\n",
            "Epoch 4, Batch 8000: Loss 0.788\n",
            "Epoch 4, Batch 10000: Loss 0.768\n",
            "Epoch 4, Batch 12000: Loss 0.764\n",
            "Epoch 5, Batch 2000: Loss 0.635\n",
            "Epoch 5, Batch 4000: Loss 0.655\n",
            "Epoch 5, Batch 6000: Loss 0.667\n",
            "Epoch 5, Batch 8000: Loss 0.678\n",
            "Epoch 5, Batch 10000: Loss 0.660\n",
            "Epoch 5, Batch 12000: Loss 0.669\n",
            "Epoch 6, Batch 2000: Loss 0.523\n",
            "Epoch 6, Batch 4000: Loss 0.539\n",
            "Epoch 6, Batch 6000: Loss 0.560\n",
            "Epoch 6, Batch 8000: Loss 0.565\n",
            "Epoch 6, Batch 10000: Loss 0.590\n",
            "Epoch 6, Batch 12000: Loss 0.598\n",
            "Epoch 7, Batch 2000: Loss 0.420\n",
            "Epoch 7, Batch 4000: Loss 0.432\n",
            "Epoch 7, Batch 6000: Loss 0.461\n",
            "Epoch 7, Batch 8000: Loss 0.484\n",
            "Epoch 7, Batch 10000: Loss 0.524\n",
            "Epoch 7, Batch 12000: Loss 0.519\n",
            "Epoch 8, Batch 2000: Loss 0.316\n",
            "Epoch 8, Batch 4000: Loss 0.344\n",
            "Epoch 8, Batch 6000: Loss 0.374\n",
            "Epoch 8, Batch 8000: Loss 0.415\n",
            "Epoch 8, Batch 10000: Loss 0.422\n",
            "Epoch 8, Batch 12000: Loss 0.446\n",
            "Epoch 9, Batch 2000: Loss 0.265\n",
            "Epoch 9, Batch 4000: Loss 0.287\n",
            "Epoch 9, Batch 6000: Loss 0.309\n",
            "Epoch 9, Batch 8000: Loss 0.370\n",
            "Epoch 9, Batch 10000: Loss 0.373\n",
            "Epoch 9, Batch 12000: Loss 0.380\n",
            "Epoch 10, Batch 2000: Loss 0.220\n",
            "Epoch 10, Batch 4000: Loss 0.226\n",
            "Epoch 10, Batch 6000: Loss 0.246\n",
            "Epoch 10, Batch 8000: Loss 0.275\n",
            "Epoch 10, Batch 10000: Loss 0.312\n",
            "Epoch 10, Batch 12000: Loss 0.295\n",
            "Training finished\n",
            "Accuracy of CNN on the test set: 67.83%\n",
            "Average loss of CNN on the test set: 1.3539\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transfer Learning with VGG**"
      ],
      "metadata": {
        "id": "P6PAyIT_pLAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "\n",
        "# Check if CUDA is available and set device accordingly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# Define transformations and load CIFAR-10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize images to VGG input size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "# Load pre-trained VGG model and modify for CIFAR-10\n",
        "vgg_model = models.vgg16(pretrained=True)\n",
        "vgg_model.to(device)  # Move model to GPU if available\n",
        "\n",
        "for param in vgg_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "num_features = vgg_model.classifier[6].in_features\n",
        "vgg_model.classifier[6] = nn.Linear(num_features, 10)  # 10 classes in CIFAR-10\n",
        "vgg_model.to(device)  # Move modified model to GPU if available\n",
        "\n",
        "# Define loss function, optimizer, and number of epochs\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(vgg_model.classifier.parameters(), lr=0.001, momentum=0.9)\n",
        "num_epochs = 10\n",
        "\n",
        "# Train the adapted VGG model\n",
        "vgg_model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)  # Move data to GPU if available\n",
        "        optimizer.zero_grad()\n",
        "        outputs = vgg_model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:\n",
        "            print(f'Epoch {epoch + 1}, Batch {i + 1}: Loss {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Training finished')\n",
        "\n",
        "# Evaluate the adapted VGG model on the test set\n",
        "correct = 0\n",
        "total = 0\n",
        "test_loss = 0.0\n",
        "\n",
        "vgg_model.eval()\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)  # Move data to GPU if available\n",
        "        outputs = vgg_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "accuracy_vgg = 100 * correct / total\n",
        "average_test_loss_vgg = test_loss / len(testloader)\n",
        "\n",
        "print(f'Accuracy of VGG on the test set: {accuracy_vgg:.2f}%')\n",
        "print(f'Average loss of VGG on the test set: {average_test_loss_vgg:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3fH8hKbpkWQ",
        "outputId": "fcb256fe-ba9a-4869-e8ce-3f77b7eb2d10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Training finished\n",
            "Accuracy of VGG on the test set: 80.19%\n",
            "Average loss of VGG on the test set: 0.5711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis and Discussion\n",
        "\n",
        "## Comparison of Test Set Accuracy and Loss:\n",
        "\n",
        "- **MLP**:\n",
        "  - Accuracy: 53.67%\n",
        "  - Average Loss: 1.5095\n",
        "\n",
        "- **CNN**:\n",
        "  - Accuracy: 67.83%\n",
        "  - Average Loss: 1.3539\n",
        "\n",
        "- **VGG-based Model**:\n",
        "  - Accuracy: 80.19%\n",
        "  - Average Loss: 0.5711\n",
        "\n",
        "## Reasons Behind Performance Differences:\n",
        "\n",
        "### CNN vs. MLP:\n",
        "CNNs perform better than MLPs in image classification tasks due to their ability to leverage the spatial structure of images. CNNs use convolutional layers to extract features hierarchically, preserving the spatial relationships between pixels. This allows CNNs to capture local patterns and spatial dependencies, leading to better feature extraction and classification performance compared to MLPs, which treat images as flattened vectors and do not consider spatial information.\n",
        "\n",
        "### VGG-based Model vs. CNN:\n",
        "The VGG-based model, which is a deeper CNN architecture with more complex feature extraction capabilities, outperforms the simpler CNN in terms of accuracy and loss. The VGG model has learned rich and diverse features from a large-scale dataset like ImageNet during pre-training. Transfer learning from the pre-trained VGG model provides a significant advantage by initializing the network with meaningful weights, allowing the model to converge faster and achieve better performance on the CIFAR-10 dataset.\n",
        "\n",
        "## Benefits of Transfer Learning with VGG:\n",
        "\n",
        "- Transfer learning with the VGG model has helped improve both accuracy and loss on the CIFAR-10 dataset. The pre-trained VGG model has already learned to recognize a wide variety of features from ImageNet, which are transferable to CIFAR-10.\n",
        "- The VGG model's hierarchical feature extraction capabilities, combined with transfer learning, enable the model to learn more complex and discriminative features specific to CIFAR-10 classes, resulting in improved accuracy.\n",
        "- Additionally, transfer learning reduces training time and computational resources required to train a deep model from scratch. The VGG model serves as a powerful feature extractor, and fine-tuning the model on CIFAR-10 allows it to adapt to the specific characteristics of the dataset while leveraging the general knowledge learned from ImageNet.\n",
        "\n",
        "In conclusion, CNNs, especially deeper architectures like the VGG model with transfer learning, outperform MLPs in image classification tasks due to their ability to capture spatial features and leverage pre-trained knowledge from large-scale datasets. Transfer learning with pre-trained models like VGG can significantly improve performance, reduce training time, and enhance the overall effectiveness of deep learning models on specific tasks.\n"
      ],
      "metadata": {
        "id": "e_HVzXSU8Gun"
      }
    }
  ]
}
